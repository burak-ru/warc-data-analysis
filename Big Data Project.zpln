{
  "paragraphs": [
    {
      "text": "%md\n# Big Data Project - Burak Balci\n## Frequency of Covid Related Terms\n\nThe goal of this project is to analyse the  covid related websites from the 2021 April web crawl. Our goal is to find the websites there are related to Covid-19, which was still a daily topic in 2021. Each step took for this assignment is explained by a text block right before the code block. ",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:51:43+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h1>Big Data Project - Burak Balci</h1>\n<h2>Frequency of Covid Related Terms</h2>\n<p>The goal of this project is to analyse the  covid related websites from the 2021 April web crawl. Our goal is to find the websites there are related to Covid-19, which was still a daily topic in 2021. Each step took for this assignment is explained by a text block right before the code block.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719176434994_2096245804",
      "id": "paragraph_1719176434994_2096245804",
      "dateCreated": "2024-06-23T21:00:34+0000",
      "dateStarted": "2024-06-24T15:51:43+0000",
      "dateFinished": "2024-06-24T15:51:46+0000",
      "status": "FINISHED",
      "focus": true,
      "$$hashKey": "object:10014"
    },
    {
      "text": "%md\n## Setup The Environment\n\nIn this section we will handle interactive file input and our Spark settings.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:51:46+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Setup The Environment</h2>\n<p>In this section we will handle interactive file input and our Spark settings.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719186036549_1135649540",
      "id": "paragraph_1719186036549_1135649540",
      "dateCreated": "2024-06-23T23:40:36+0000",
      "dateStarted": "2024-06-24T15:51:46+0000",
      "dateFinished": "2024-06-24T15:51:46+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10015"
    },
    {
      "text": "%md\nWe will import the libraries needed for this project.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:51:46+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We will import the libraries needed for this project.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719176491499_307755622",
      "id": "paragraph_1719176491499_307755622",
      "dateCreated": "2024-06-23T21:01:31+0000",
      "dateStarted": "2024-06-24T15:51:46+0000",
      "dateFinished": "2024-06-24T15:51:46+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10016"
    },
    {
      "text": "import org.apache.hadoop.io.NullWritable\nimport de.l3s.concatgz.io.warc.{WarcGzInputFormat, WarcWritable}\nimport de.l3s.concatgz.data.WarcRecord\nimport org.apache.spark.SparkConf\nimport org.apache.spark.sql.SparkSession\nimport org.jsoup.Jsoup\nimport org.apache.commons.lang3.StringUtils\nimport org.jsoup.nodes.{Document,Element}\nimport collection.JavaConverters._\nimport org.apache.spark.sql.functions._",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:51:46+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.hadoop.io.NullWritable\nimport de.l3s.concatgz.io.warc.{WarcGzInputFormat, WarcWritable}\nimport de.l3s.concatgz.data.WarcRecord\nimport org.apache.spark.SparkConf\nimport org.apache.spark.sql.SparkSession\nimport org.jsoup.Jsoup\nimport org.apache.commons.lang3.StringUtils\nimport org.jsoup.nodes.{Document, Element}\nimport collection.JavaConverters._\nimport org.apache.spark.sql.functions._\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719185102257_2121720995",
      "id": "paragraph_1719185102257_2121720995",
      "dateCreated": "2024-06-23T23:25:02+0000",
      "dateStarted": "2024-06-24T15:51:46+0000",
      "dateFinished": "2024-06-24T15:52:00+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10017"
    },
    {
      "text": "%md\nWe need to configure our Spark Context settings.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:00+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We need to configure our Spark Context settings.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719198503957_475246614",
      "id": "paragraph_1719198503957_475246614",
      "dateCreated": "2024-06-24T03:08:23+0000",
      "dateStarted": "2024-06-24T15:52:00+0000",
      "dateFinished": "2024-06-24T15:52:00+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10018"
    },
    {
      "text": "val sparkConf = new SparkConf()\n    .setAppName(\"RUBigData Covid\")\n    .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n    .registerKryoClasses(Array(classOf[WarcRecord]))\n\nimplicit val sparkSession = SparkSession.builder().config(sparkConf).getOrCreate()\nval sc = sparkSession.sparkContext",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:01+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34msparkConf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.SparkConf\u001b[0m = org.apache.spark.SparkConf@4ee2cf4b\n\u001b[1m\u001b[34msparkSession\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.SparkSession\u001b[0m = org.apache.spark.sql.SparkSession@2d64f8a8\n\u001b[1m\u001b[34msc\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.SparkContext\u001b[0m = org.apache.spark.SparkContext@fbc7e3\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719198505710_1522503545",
      "id": "paragraph_1719198505710_1522503545",
      "dateCreated": "2024-06-24T03:08:25+0000",
      "dateStarted": "2024-06-24T15:52:01+0000",
      "dateFinished": "2024-06-24T15:52:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10019"
    },
    {
      "text": "%md\nThis will create a textbox where we can input the filename for the WARC file that we will use.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:02+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>This will create a textbox where we can input the filename for the WARC file that we will use.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719198507013_346601712",
      "id": "paragraph_1719198507013_346601712",
      "dateCreated": "2024-06-24T03:08:27+0000",
      "dateStarted": "2024-06-24T15:52:02+0000",
      "dateFinished": "2024-06-24T15:52:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10020"
    },
    {
      "text": "val fname = z.textbox(\"Filename:\")\nval warcfile = s\"file:///opt/hadoop/rubigdata/${fname}.warc.gz\"",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:02+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {
          "Filename:": "CC-MAIN-20210410105831-20210410135831-00639"
        },
        "forms": {
          "Filename:": {
            "type": "TextBox",
            "name": "Filename:",
            "displayName": "Filename:",
            "defaultValue": "",
            "hidden": false,
            "$$hashKey": "object:10283"
          }
        }
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mfname\u001b[0m: \u001b[1m\u001b[32mObject\u001b[0m = CC-MAIN-20210410105831-20210410135831-00639\n\u001b[1m\u001b[34mwarcfile\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m = file:///opt/hadoop/rubigdata/CC-MAIN-20210410105831-20210410135831-00639.warc.gz\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719185304327_1826856130",
      "id": "paragraph_1719185304327_1826856130",
      "dateCreated": "2024-06-23T23:28:24+0000",
      "dateStarted": "2024-06-24T15:52:02+0000",
      "dateFinished": "2024-06-24T15:52:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10021"
    },
    {
      "text": "%md\nWe will split the WARC file to WARC records.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:02+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We will split the WARC file to WARC records.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719185738660_407913735",
      "id": "paragraph_1719185738660_407913735",
      "dateCreated": "2024-06-23T23:35:38+0000",
      "dateStarted": "2024-06-24T15:52:02+0000",
      "dateFinished": "2024-06-24T15:52:02+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10022"
    },
    {
      "text": "val warcs = sc.newAPIHadoopFile(\n              warcfile,\n              classOf[WarcGzInputFormat],             // InputFormat\n              classOf[NullWritable],                  // Key\n              classOf[WarcWritable]                   // Value\n    ).cache()",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:03+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mwarcs\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(org.apache.hadoop.io.NullWritable, de.l3s.concatgz.io.warc.WarcWritable)]\u001b[0m = file:///opt/hadoop/rubigdata/CC-MAIN-20210410105831-20210410135831-00639.warc.gz NewHadoopRDD[0] at newAPIHadoopFile at <console>:42\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719185429469_409987933",
      "id": "paragraph_1719185429469_409987933",
      "dateCreated": "2024-06-23T23:30:29+0000",
      "dateStarted": "2024-06-24T15:52:03+0000",
      "dateFinished": "2024-06-24T15:52:03+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10023"
    },
    {
      "text": "%md\n## Analysis\n\nIn this section we will analyse the data. The main goal is to find out how many websites are related to Covid-19. We will create a data frame by filtering our WARC records and use SQL on the data frame. To count a website as covid related, it should either contain a covid related word in it's title, url or in it's content. Although I doubt that a website having a title related to covid and not having a single mention in its content, we will still do a double check on title and url.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:03+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Analysis</h2>\n<p>In this section we will analyse the data. The main goal is to find out how many websites are related to Covid-19. We will create a data frame by filtering our WARC records and use SQL on the data frame. To count a website as covid related, it should either contain a covid related word in it&rsquo;s title, url or in it&rsquo;s content. Although I doubt that a website having a title related to covid and not having a single mention in its content, we will still do a double check on title and url.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719185986568_1991687094",
      "id": "paragraph_1719185986568_1991687094",
      "dateCreated": "2024-06-23T23:39:46+0000",
      "dateStarted": "2024-06-24T15:52:03+0000",
      "dateFinished": "2024-06-24T15:52:03+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10024"
    },
    {
      "text": "%md\nWe will filter and map our records such that we end up with the title, url, and count of the covid related terms in content of the record.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:04+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>We will filter and map our records such that we end up with the title, url, and count of the covid related terms in content of the record.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719187732750_239761253",
      "id": "paragraph_1719187732750_239761253",
      "dateCreated": "2024-06-24T00:08:52+0000",
      "dateStarted": "2024-06-24T15:52:04+0000",
      "dateFinished": "2024-06-24T15:52:04+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10025"
    },
    {
      "text": "val filteredWarcs = warcs.map{ wr => wr._2 }.\n                        filter{ _.isValid() }.\n                        map{ _.getRecord() }.\n                        filter{ _.getHeader().getHeaderValue(\"WARC-Type\") == \"response\" }.\n                        map { wr => {\n                            val url = wr.getHeader().getUrl()\n                            (wr, url)\n                            }\n                        }.\n                        map { wr => (wr._1.getHttpStringBody(), wr._2) }.\n                        filter { _._1.length > 0 }.\n                        map { wr => (Jsoup.parse(wr._1), wr._2) }.\n                        map { wr => {\n                                val title = wr._1.title().toLowerCase()\n                                val url = wr._2\n                                val content = wr._1.body().text().toLowerCase()\n                                val covidCount = StringUtils.countMatches(content, \"covid\")\n                                val covid19Count = StringUtils.countMatches(content, \"covid-19\")\n                                val coronaCount = StringUtils.countMatches(content, \"corona\")\n                                val pandemicCount = StringUtils.countMatches(content, \"pandemic\")\n                                val sarsCount = StringUtils.countMatches(content, \"sars-cov-2\")\n                                (title, url, covidCount+covid19Count+coronaCount+pandemicCount+sarsCount)\n                            } \n                        }.\n                        filter{ wr => wr._1.length > 0 && wr._2.length > 0 }",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:04+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mfilteredWarcs\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.rdd.RDD[(String, String, Int)]\u001b[0m = MapPartitionsRDD[10] at filter at <console>:65\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719197264104_210756209",
      "id": "paragraph_1719197264104_210756209",
      "dateCreated": "2024-06-24T02:47:44+0000",
      "dateStarted": "2024-06-24T15:52:04+0000",
      "dateFinished": "2024-06-24T15:52:04+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10026"
    },
    {
      "text": "%md\nNow, we can create DF using our WARC records.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:04+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Now, we can create DF using our WARC records.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719186178494_1657713788",
      "id": "paragraph_1719186178494_1657713788",
      "dateCreated": "2024-06-23T23:42:58+0000",
      "dateStarted": "2024-06-24T15:52:04+0000",
      "dateFinished": "2024-06-24T15:52:04+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10027"
    },
    {
      "text": "val DF = filteredWarcs.toDF(\"title\", \"url\", \"count\")\nDF.createOrReplaceTempView(\"DataFrame\")\nDF.show(10)",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:04+0000",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+------------------------------------+--------------------+-----+\n|                               title|                 url|count|\n+------------------------------------+--------------------+-----+\n|                we are here to em...|http://000directo...|    0|\n|                พนันบอลออนไลน์ เว...|http://0102030405...|    0|\n|                 南京地产_广告位测试|http://025dc.com/...|    0|\n|南京地产_代餐粉！下一个行业新风口...|http://025dc.com/...|    0|\n|    包装机械供应信息--产品库--我帮网|http://0314.wreck...|    0|\n|  《20巨乳妹超迷你比基尼游泳大会2...|http://0370shop.c...|    0|\n|                الغول في قبضة الش...|http://04.ma/2016...|    0|\n|                     唐詩-洪爺av貼圖|http://0401a.9659...|    0|\n|        代开医院证明微信178728950...|  http://045607.com/|    0|\n|         0509視訊美女網 - 視訊 - ...|http://0509-vip.c...|    0|\n+------------------------------------+--------------------+-----+\nonly showing top 10 rows\n\n\u001b[1m\u001b[34mDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [title: string, url: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://d2fdb6d159e1:4040/jobs/job?id=0",
              "$$hashKey": "object:11245"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719193047084_218933834",
      "id": "paragraph_1719193047084_218933834",
      "dateCreated": "2024-06-24T01:37:27+0000",
      "dateStarted": "2024-06-24T15:52:04+0000",
      "dateFinished": "2024-06-24T15:52:10+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10028"
    },
    {
      "text": "%md\nFinally, we will filter the data frame to records that either has a covid related term in their title or url, or has more than one occurance of a covid related term in their content.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:52:10+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<p>Finally, we will filter the data frame to records that either has a covid related term in their title or url, or has more than one occurance of a covid related term in their content.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719194703220_24900624",
      "id": "paragraph_1719194703220_24900624",
      "dateCreated": "2024-06-24T02:05:03+0000",
      "dateStarted": "2024-06-24T15:52:10+0000",
      "dateFinished": "2024-06-24T15:52:10+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10029"
    },
    {
      "text": "val filteredDF = spark.sql(\n    \"\"\"\n    SELECT * FROM DataFrame\n    WHERE title LIKE '%covid%'\n    OR title LIKE '%covid-19%'\n    OR title LIKE '%corona%'\n    OR title LIKE '%pandemic%'\n    OR title LIKE '%sars-cov-2%'\n    OR url LIKE '%covid%'\n    OR url LIKE '%covid-19%'\n    OR url LIKE '%corona%'\n    OR url LIKE '%pandemic%'\n    OR url LIKE '%sars-cov-2%'\n    OR count > 0\n    \"\"\")\n    \nfilteredDF.createOrReplaceTempView(\"FilteredDataFrame\")\nfilteredDF.show(10)\n",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:54:46+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12,
        "editorMode": "ace/mode/scala",
        "fontSize": 9,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------------------+--------------------+-----+\n|               title|                 url|count|\n+--------------------+--------------------+-----+\n|funeral homes in ...|http://10secondre...|    9|\n|взгляд / сша внес...|http://5smi.ru/?p...|    1|\n|últim sopar líric...|http://7portes.co...|    2|\n|putas asiaticas e...|http://abnehmenoh...|    1|\n|articles by ritik...|http://admin.outl...|    3|\n|el punt avui - re...|http://admin2014....|    1|\n|england tour of s...|http://agronautas...|   27|\n|en iyi fatih sult...|http://ali.tv.tr/...|    1|\n|crystallion - a d...|http://alllossles...|    1|\n|oppressor - agony...|http://alllossles...|    1|\n+--------------------+--------------------+-----+\nonly showing top 10 rows\n\n\u001b[1m\u001b[34mfilteredDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m = [title: string, url: string ... 1 more field]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://d2fdb6d159e1:4040/jobs/job?id=11",
              "$$hashKey": "object:11349"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719193042574_375861700",
      "id": "paragraph_1719193042574_375861700",
      "dateCreated": "2024-06-24T01:37:22+0000",
      "dateStarted": "2024-06-24T15:54:46+0000",
      "dateFinished": "2024-06-24T15:54:49+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10030"
    },
    {
      "text": "%md\n## Conclusion\n\nWe have successfully filtered WARC records to only covid related ones. Now we can see the records that are related to covid, their title, url and how many words related to covid they have.",
      "user": "anonymous",
      "dateUpdated": "2024-06-24T15:53:07+0000",
      "progress": 0,
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12,
        "editorMode": "ace/mode/markdown",
        "fontSize": 9,
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "<div class=\"markdown-body\">\n<h2>Conclusion</h2>\n<p>We have successfully filtered WARC records to only covid related ones. Now we can see the records that are related to covid, their title, url and how many words related to covid they have.</p>\n\n</div>"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1719195828185_1650800041",
      "id": "paragraph_1719195828185_1650800041",
      "dateCreated": "2024-06-24T02:23:48+0000",
      "dateStarted": "2024-06-24T15:53:07+0000",
      "dateFinished": "2024-06-24T15:53:07+0000",
      "status": "FINISHED",
      "$$hashKey": "object:10031"
    }
  ],
  "name": "Big Data Project",
  "id": "2K3SN2VZZ",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false,
    "looknfeel": "default",
    "personalizedMode": "false"
  },
  "info": {
    "isRunning": false
  },
  "path": "/Big Data Project"
}